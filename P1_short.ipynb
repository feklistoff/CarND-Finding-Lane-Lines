{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n",
    "---\n",
    "In this project I used OpenCV, NumPy and Jupyter Notebook for road lane lines detection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Here are my steps for completeing this project **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put the pipeline into a class. This allows us to have a convinient way to represent developed pipeline as well as add some helpful features such as buffering. Buffering helps us to fill missing frames with averaged approximation and get rid of jittering lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque # this makes buffer of constant length and automatically keeps it updated\n",
    "                              # deleting first item in the list\n",
    "\n",
    "class LaneTracker:\n",
    "    def __init__(self):\n",
    "        # for unified size\n",
    "        self.width           = 960\n",
    "        self.height          = 540\n",
    "        # for canny edges\n",
    "        self.low_threshold   = 50\n",
    "        self.high_threshold  = 150\n",
    "        # for blurring/smoothing\n",
    "        self.kernel_size     = 5\n",
    "        # for hough lines\n",
    "        self.rho             = 1\n",
    "        self.theta           = np.pi/180\n",
    "        self.threshold       = 40\n",
    "        self.min_line_len    = 40\n",
    "        self.max_line_gap    = 250\n",
    "        # for avoiding outliers\n",
    "        self.min_left_slope  = 0.5\n",
    "        self.max_left_slope  = 0.7\n",
    "        self.min_right_slope = -0.9\n",
    "        self.max_right_slope = -0.5\n",
    "        # for filling the gaps\n",
    "        self.buffer_left          = deque(maxlen=5)\n",
    "        self.buffer_right         = deque(maxlen=5)\n",
    "    \n",
    "    def resize(self, img):\n",
    "        return cv2.resize(img,(self.width, self.height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "    def yellow_white_masks(self, img):\n",
    "        # convert to HSL\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        # find white lane\n",
    "        lower_white = np.array([0, 190, 0], dtype=np.uint8)\n",
    "        upper_white = np.array([180, 255, 255], dtype=np.uint8)\n",
    "        white_mask = cv2.inRange(img, lower_white, upper_white)\n",
    "        # find yellow lane\n",
    "        lower_yellow = np.array([0, 70, 100], dtype=np.uint8)\n",
    "        upper_yellow = np.array([100, 250, 255], dtype=np.uint8)\n",
    "        yellow_mask = cv2.inRange(img, lower_yellow, upper_yellow)\n",
    "        # combine yellow and white\n",
    "        yell_white = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "        masked = cv2.bitwise_and(img, img, mask=yell_white)\n",
    "        return masked\n",
    "    \n",
    "    def grayscale(self, img):\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    def gaussian_blur(self, img, kernel_size):\n",
    "        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    \n",
    "    def canny(self, img, low_threshold, high_threshold):\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "    def find_vertices(self, imshape):\n",
    "        bottom_left = (0, imshape[0])\n",
    "        bottom_right = (imshape[1], imshape[0])\n",
    "        top_left = ((imshape[1]/2 - imshape[1]*0.03), imshape[0]/1.6)\n",
    "        top_right = ((imshape[1]/2 + imshape[1]*0.03), imshape[0]/1.6)\n",
    "        vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "        return vertices\n",
    "    \n",
    "    def region_of_interest(self, img):\n",
    "        vertices  = self.find_vertices(img.shape)\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)   \n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "        #filling pixels inside the polygon defined by vertices with the fill color    \n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "    \n",
    "    def lines_filter(self, lines):\n",
    "        # Right lines: slope < 0; Left lines:  slope > 0 \n",
    "        right_line_parameters = []\n",
    "        left_line_parameters = []\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                if x1==x2 or y1==y2:\n",
    "                    continue\n",
    "                slope  = ((y2-y1)/(x2-x1))\n",
    "                intercept = y1 - slope*x1\n",
    "                # initalizing slope control and keep only lines of interest\n",
    "                if slope > 0 and slope > self.min_left_slope and slope < self.max_left_slope:\n",
    "                    left_line_parameters.append([slope, intercept])\n",
    "                if slope < 0 and slope > self.min_right_slope and slope < self.max_right_slope:\n",
    "                    right_line_parameters.append([slope, intercept])\n",
    "        # average parameters to form only one line per detected lane\n",
    "        right_slope_intercept = np.mean(right_line_parameters, axis=0)\n",
    "        left_slope_intercept = np.mean(left_line_parameters, axis=0)\n",
    "        return right_slope_intercept, left_slope_intercept\n",
    "\n",
    "    def line_endpoints(self, shape, slope_intercept):\n",
    "        # check if some missing values (meaning no line detected)\n",
    "        try:\n",
    "            slope = slope_intercept[0]\n",
    "            intercept = slope_intercept[1]\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "        slope = slope_intercept[0]\n",
    "        intercept = slope_intercept[1]\n",
    "        y1 = int(shape[0])\n",
    "        x1 = int((y1 - intercept)/slope)\n",
    "        y2 = int(shape[0]/1.6)\n",
    "        x2 = int((y2 - intercept)/slope)\n",
    "        return [x1, y1, x2, y2]\n",
    "\n",
    "    def two_hough_lines(self, img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "        # hough transform\n",
    "        lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len,\n",
    "                                maxLineGap=max_line_gap)\n",
    "        line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "        # calculate average left and right slope/intercept in order to draw a single line for each lane\n",
    "        right_slope_intercept, left_slope_intercept = self.lines_filter(lines)\n",
    "        # find endopints for lines to draw \n",
    "        shape = img.shape\n",
    "        right_line = self.line_endpoints(shape, right_slope_intercept)\n",
    "        left_line = self.line_endpoints(shape, left_slope_intercept)\n",
    "        # check if lines detected successfully\n",
    "        if right_line is None:\n",
    "            if self.buffer_right:\n",
    "                right_line = np.mean(self.buffer_right, axis=0, dtype=np.uint32)\n",
    "        if left_line is None:\n",
    "            if self.buffer_left:\n",
    "                left_line = np.mean(self.buffer_left, axis=0, dtype=np.uint32)\n",
    "        else:\n",
    "            self.buffer_right.append(right_line)\n",
    "            self.buffer_left.append(left_line)\n",
    "            right_line = np.mean(self.buffer_right, axis=0, dtype=np.uint32)\n",
    "            left_line = np.mean(self.buffer_left, axis=0, dtype=np.uint32)\n",
    "        # draw lines\n",
    "        two_lines = [right_line, left_line]\n",
    "        color = [255, 0, 0]\n",
    "        thickness = 10\n",
    "        for line in two_lines:\n",
    "            cv2.line(line_img, (line[0], line[1]), (line[2], line[3]), color, thickness)\n",
    "        return line_img\n",
    "\n",
    "    def weighted_img(self, img, initial_img, α=0.8, β=1., λ=0.):\n",
    "        return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "    def process_image(self, image):\n",
    "        if image.shape[0] > 540 and image.shape[1] > 960:\n",
    "            image     = self.resize(image)\n",
    "        masked    = self.yellow_white_masks(image)\n",
    "        gray      = self.grayscale(masked)\n",
    "        blur      = self.gaussian_blur(gray, self.kernel_size)\n",
    "        edges     = self.canny(blur, self.low_threshold, self.high_threshold)\n",
    "        roi       = self.region_of_interest(edges)\n",
    "        two_lines = self.two_hough_lines(roi, self.rho, self.theta, self.threshold, self.min_line_len, \n",
    "                                         self.max_line_gap)\n",
    "        result    = self.weighted_img(two_lines, image)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's try our class on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_white = LaneTracker()\n",
    "white_out = 'test_videos_output/solidWhiteRightUpgraded.mp4'\n",
    "# clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "# white_clip = clip1.fl_image(tracker_white.process_image)\n",
    "# %time white_clip.write_videofile(white_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRightUpgraded.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_yellow = LaneTracker()\n",
    "yellow_out = 'test_videos_output/solidYellowLeftUpgraded.mp4'\n",
    "# clip1 = VideoFileClip(\"test_videos/solidYellowLeft.mp4\")\n",
    "# yellow_clip = clip1.fl_image(tracker_yellow.process_image)\n",
    "# %time yellow_clip.write_videofile(yellow_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeftUpgraded.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## And, of course, Challenge video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_challenge = LaneTracker()\n",
    "challenge_out = 'test_videos_output/challengeUpgraded.mp4'\n",
    "# clip1 = VideoFileClip(\"test_videos/challenge.mp4\")\n",
    "# challenge_clip = clip1.fl_image(tracker_challenge.process_image)\n",
    "# %time challenge_clip.write_videofile(challenge_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challengeUpgraded.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A Fun Part!\n",
    "\n",
    "Let's drop hardcoded region of interest and see what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add some intercept control along with the slope control\n",
    "class LaneTrackerNoRoi(LaneTracker):\n",
    "    def __init__(self):\n",
    "        # for unified size\n",
    "        self.width           = 960\n",
    "        self.height          = 540\n",
    "        # for canny edges\n",
    "        self.low_threshold   = 50\n",
    "        self.high_threshold  = 150\n",
    "        # for blurring/smoothing\n",
    "        self.kernel_size     = 5\n",
    "        # for hough lines\n",
    "        self.rho             = 1\n",
    "        self.theta           = np.pi/180\n",
    "        self.threshold       = 40\n",
    "        self.min_line_len    = 40\n",
    "        self.max_line_gap    = 250\n",
    "        # for avoiding outliers\n",
    "        self.min_left_slope  = 0.5\n",
    "        self.max_left_slope  = 0.7\n",
    "        self.min_right_slope = -0.9\n",
    "        self.max_right_slope = -0.5\n",
    "        self.min_left_intercept  = 15\n",
    "        self.max_left_intercept  = 45\n",
    "        self.min_right_intercept = 630\n",
    "        self.max_right_intercept = 690\n",
    "        # for filling gaps\n",
    "        self.buffer_left          = deque(maxlen=5)\n",
    "        self.buffer_right         = deque(maxlen=5)\n",
    "        \n",
    "    \n",
    "    def lines_filter(self, lines):\n",
    "        # Right lines: slope < 0; Left lines:  slope > 0 \n",
    "        right_line_parameters = []\n",
    "        left_line_parameters = []\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                if x1==x2 or y1==y2:\n",
    "                    continue\n",
    "                slope  = ((y2-y1)/(x2-x1))\n",
    "                intercept = y1 - slope*x1\n",
    "                if slope > 0 and slope > self.min_left_slope and slope < self.max_left_slope\\\n",
    "                and (intercept > self.min_left_intercept and intercept < self.max_left_intercept):\n",
    "                    left_line_parameters.append([slope, intercept])\n",
    "                if slope < 0 and slope > self.min_right_slope and slope < self.max_right_slope\\\n",
    "                and (intercept > self.min_right_intercept and intercept < self.max_right_intercept):\n",
    "                    right_line_parameters.append([slope, intercept])\n",
    "        right_slope_intercept = np.mean(right_line_parameters, axis=0)\n",
    "        left_slope_intercept = np.mean(left_line_parameters, axis=0)\n",
    "        return right_slope_intercept, left_slope_intercept\n",
    "\n",
    "    def process_image(self, image):\n",
    "        if image.shape[0] > 540 and image.shape[1] > 960:\n",
    "            image     = self.resize(image)\n",
    "        masked    = self.yellow_white_masks(image)\n",
    "        gray      = self.grayscale(masked)\n",
    "        blur      = self.gaussian_blur(gray, self.kernel_size)\n",
    "        edges     = self.canny(blur, self.low_threshold, self.high_threshold)\n",
    "        two_lines = self.two_hough_lines(edges, self.rho, self.theta, self.threshold, self.min_line_len, \n",
    "                                         self.max_line_gap)\n",
    "        result    = self.weighted_img(two_lines, image)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_white_noroi = LaneTrackerNoRoi()\n",
    "white_out_noroi = 'test_videos_output/solidWhiteRightNoRoi.mp4'\n",
    "# clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "# white_clip_noroi = clip1.fl_image(tracker_white_noroi.process_image)\n",
    "# %time white_clip_noroi.write_videofile(white_out_noroi, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRightNoRoi.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_out_noroi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_challenge_noroi = LaneTrackerNoRoi()\n",
    "challenge_out_noroi = 'test_videos_output/challengeNoRoi.mp4'\n",
    "# clip1 = VideoFileClip(\"test_videos/challenge.mp4\")\n",
    "# challenge_clip_noroi = clip1.fl_image(tracker_challenge_noroi.process_image)\n",
    "# %time challenge_clip_noroi.write_videofile(challenge_out_noroi, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challengeNoRoi.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_out_noroi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
